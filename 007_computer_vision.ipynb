{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afirdousi/pytorch-basics/blob/main/007_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xUy7qUBJiFui"
      },
      "outputs": [],
      "source": [
        "# Computer Vision\n",
        "\n",
        "# Examples of Problems\n",
        "# Is this photo a cricket ball or a football? (Binary Classification)\n",
        "# Is this photo a cricket ball or a football or a volleyball? (Multi Class Classification)\n",
        "# Where is the thing we are looking for? Finding something in an image (Object Detection)\n",
        "# What are the different sections in this image? (Segmentation) - Computational Photography\n",
        "# --- How do you segment different parts of the image and enhance different parts of the image\n",
        "# --- semantic masking and other operations that can be performed\n",
        "# ---- Read this for more: https://machinelearning.apple.com/research/panoptic-segmentation\n",
        "\n",
        "# Tesla Computer Vision\n",
        "# Tesla AVs have 8 cameras , they take these 8 different view points, pass it through a deep neural net and convert it into a\n",
        "# 3-dimensional \"vector space\" representation\n",
        "# Watch these:\n",
        "# https://www.youtube.com/watch?v=suv8ex8xlZA (Tesla AI day 2022 higlights)\n",
        "# https://www.youtube.com/watch?v=ODSJsviD_SU (Tesla AI day 2022)\n",
        "# https://www.youtube.com/watch?v=j0z4FweCy4M (Tesla AI day 2021)\n",
        "\n",
        "# Proof of Tesla using similar device agnostic code that we have learned in previous notebooks\n",
        "# https://www.youtube.com/watch?v=j0z4FweCy4M ( instead of cuda they use Dojo which is their own chip/accelerator)\n",
        "\n",
        "# Also check this video to visualize: https://www.youtube.com/watch?v=Vz-SyKC9qnM\n",
        "\n",
        "# More here: https://www.v7labs.com/blog/computer-vision-applications"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will focus on:\n",
        "# 1. Getting a vision dataset to work using torchvision.datasets\n",
        "# 2. Arch of a CNN with PyTorch\n",
        "# 3. An end to end multi class classification problem\n",
        "# 4. Steps in modeling with CNNs in PyTorch (create model, pick loss and optimizer, train, evaluate)"
      ],
      "metadata": {
        "id": "t1dRwxhJhipn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computer Vision Inputs and Outputs\n",
        "# Toy Problem: Take a picture and identify food\n",
        "\n",
        "# Typically, each image has a width, height and channel (r,g,b)\n",
        "# Encode them numericaly as a tensor\n",
        "# For many vision problem, an existing algorithm already exists\n",
        "# If tit doesn't you can build one\n",
        "# You can control the shape of the output, for example if you are detecting 5 things, you can output 5 probablities and so on..\n",
        "# And how do we improve our model? By showing more representative data of whats expected to be present in these images\n",
        "\n",
        "# You will find different types of models based on the vision problem you are solving (object detection vs segmentation vs something else)\n",
        "\n",
        "# The most famous Computer Vision algorithm is called CNN or Convolutional Neural Network\n",
        "# CNN performs fairly well on images\n",
        "# You can also use Transformer Architecture which also performs well on images (we will look into transformers later)"
      ],
      "metadata": {
        "id": "RLRRj13unAkm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images get represented as tensor usually in the form:\n",
        "\n",
        "# Shape = [batch_size, width, height, color_channels]\n",
        "# for example [None, 224, 224, 3] pr [32, 224, 224, 3] ---32 is a common batch size"
      ],
      "metadata": {
        "id": "3Rn94_Jsnoyt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are different numerical representations people use\n",
        "# NHWC ---> Number of images in a batch, height, width, color channels [ batch_size, height, width, color_channels]\n",
        "# NCHW ---> Number of images in a batch, color channels, height, width [ batch_size, color_channels, height, width ]\n",
        "\n",
        "# PyTorch uses NCHW"
      ],
      "metadata": {
        "id": "8BCPNbSYr3ZW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is CNN?\n",
        "# Read: https://medium.com/swlh/a-comprehensive-guide-to-convolution-neural-network-86f931e55679\n",
        "# Watch: https://www.youtube.com/watch?v=zfiSAzpy9NM&t=1s\n",
        "\n",
        "# CNNs perform window operations on different parts of the image\n",
        "# CNN in PyTorch: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "# CNN ---> out(Ni​,Coutj​​)= bias(C out of j​​) + k=0 to Cin - 1 ∑ weight (C out of j​​ , k) ⋆ input(Ni​,k)"
      ],
      "metadata": {
        "id": "boxYh7BltMlV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arcitecture of CNN:\n",
        "\n",
        "# Input images\n",
        "# --> input layer (takes in target images and pre processes them for further layers) ( NHWC or NCHW format )\n",
        "# -----> Concolution layer (extracts/learns the most important features from target images) (torch.nn.ConvXd)\n",
        "# -------> Hidden activation / non-linear activation (add non-linearity to learn features i.e non straight lines) ( torch.nn.ReLU)\n",
        "# ----------> Pooling Layer ( reduces the dimentionality of learned image features) (torch.nn.MaxPool2d)\n",
        "# --------------> Output layer/linear layer ( takes the learned features and output them in shape of target labels) (torch.nn.Linear)\n",
        "# -------------------> Converts output logits to prediction probablities (torch.sigmoid)\n",
        "\n",
        "# The above is a basic CNN arch\n",
        "# We can and will be building much more complex archs"
      ],
      "metadata": {
        "id": "QO_eKWbUuDZC"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyYr7CaJCGD5VN3KYMpcph",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}