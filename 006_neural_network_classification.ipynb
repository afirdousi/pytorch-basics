{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgv9rtA8KD7HCxwQEsjdjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afirdousi/pytorch-basics/blob/main/006_neural_network_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGVB137YiFAs",
        "outputId": "a83b2fb0-8bfd-4046-b915-3b6ce1d79ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version = 2.0.1+cu118\n",
            "Using device = cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using PyTorch version = { torch.__version__ }\")\n",
        "print(f\"Using device = { device }\")  # We will be doing device agnostic code in this tutorial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification\n",
        "\n",
        "# Types & Examples:\n",
        "# Binary Class Classification: Spam vs Not Spam | Dog or Cat?\n",
        "# Multiclass Classification: Sushi or Pizza or Biryani? | Dog or Cat or Tiger or Cow or whatever ...\n",
        "# Multi Label Classification: One record has multiple labels like classifying a news into multiple categories or categorizing a wikipedia article to attach relevant categories to the page"
      ],
      "metadata": {
        "id": "xUy7qUBJiFui"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Inputs and Outputs\n",
        "\n",
        "# Example:\n",
        "\n",
        "# Input (Picture) ---> ML Algo ---> Output (Label)\n",
        "\n",
        "# Input\n",
        "  # Genreally computer vision problems, convert pictures into 224x224\n",
        "  # Each pictures has W = 224, H = 224 and C = 3 ... C here is color channels R,G,B\n",
        "  # We create a numerical encoding of that like\n",
        "  # [\n",
        "  #     [0.31] [0.62], [0.44],\n",
        "  #     [0.29] [0.95], [0.0.16],\n",
        "  #     ...\n",
        "  # ]\n",
        "\n",
        "# ML Algo\n",
        "  # Often exists for the type of problem you are solving\n",
        "  # If not, you can create a new one\n",
        "\n",
        "# Output\n",
        "  # These are preidtion probabilities\n",
        "  # For eaxmple, if we are predicting if the picture is sushi, burger or pizze,\n",
        "  # For each input, we might return probablity of this image being either one\n",
        "\n",
        "  # something like [0.97, 0.00, 0.03] i.e 97% chance its a sushi\n"
      ],
      "metadata": {
        "id": "p61wJr9ji3N4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and Output shapes\n",
        "\n",
        "# For example, image input is represented something like:\n",
        "\n",
        "# [ batch_size, color_channels, width, height ] # the sequence of this can change, doesn't matter\n",
        "\n",
        "# Example:\n",
        "# Shape = [ None, 3, 224, 224 ]\n",
        "# or\n",
        "# Shape = [ 32, 3, 224, 224 ] # 32 is a common batch size\n",
        "# Check https://twitter.com/ylecun/status/989610208497360896?s=20\n",
        "# Batch size is saying train on 32 images at once\n",
        "\n",
        "\n",
        "# Output for multiclass like sushi, burger or biryani\n",
        "# Shape = [3]"
      ],
      "metadata": {
        "id": "nWMRbzxAjv20"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of a Classification Model\n",
        "\n",
        "# Define sequential input layers: number of in_features and number of out_features\n",
        "\n",
        "# for example:\n",
        "\n",
        "# in_features define the number of neurons per layer\n",
        "fun_model = nn.Sequential(\n",
        "    nn.Linear(in_features = 3, out_features= 100), # input layer\n",
        "    nn.Linear(in_features = 100, out_features= 100), # hidden layer\n",
        "    nn.ReLU(), # hidden activation layer # More here: https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
        "    nn.Linear(in_features = 100, out_features= 3) # output layer\n",
        ")\n",
        "\n",
        "# There is also output layer activation like Sigmoid (torch.sigmoid) for binary classification or Softmax (torch.softmax) for multiclass classification\n",
        "# You will also define Loss function: Binary Crossentropy (torch.nn.BCELoss) for binary classification AND Cross Entropy (torch.nn.CrossEntropyLoss) for multiclass classification\n",
        "# You will also define Optimizer function: SGD, Adam (see torch.optim) --> applies for both binary and multiclass classification"
      ],
      "metadata": {
        "id": "JLzwj2z9mBjW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fun_model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYUy9E-nR6D",
        "outputId": "99a480c2-24b6-474b-a5b0-4c54a28b165d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[-0.5668,  0.1125,  0.0617],\n",
              "                      [-0.3779, -0.4895, -0.4872],\n",
              "                      [ 0.1916,  0.0400,  0.3436],\n",
              "                      [ 0.3215, -0.1303, -0.1735],\n",
              "                      [-0.4442,  0.1094, -0.2282],\n",
              "                      [-0.4222, -0.0020, -0.5535],\n",
              "                      [ 0.1413, -0.0788,  0.2773],\n",
              "                      [-0.0040,  0.0065, -0.3290],\n",
              "                      [ 0.3223,  0.3576,  0.4861],\n",
              "                      [ 0.3635,  0.5611,  0.5202],\n",
              "                      [ 0.3831, -0.3791,  0.3612],\n",
              "                      [ 0.0448, -0.2140,  0.1948],\n",
              "                      [-0.4230,  0.4305, -0.2996],\n",
              "                      [ 0.4768, -0.2743, -0.3628],\n",
              "                      [ 0.5444, -0.3661, -0.3216],\n",
              "                      [ 0.0628, -0.5092,  0.0734],\n",
              "                      [ 0.4263, -0.1445, -0.3409],\n",
              "                      [ 0.3257,  0.3870,  0.2601],\n",
              "                      [-0.2123, -0.4786, -0.3752],\n",
              "                      [-0.5013,  0.5329,  0.4929],\n",
              "                      [ 0.0667, -0.3461,  0.3609],\n",
              "                      [-0.4454,  0.0411, -0.0587],\n",
              "                      [ 0.0908,  0.1266, -0.4066],\n",
              "                      [ 0.5494,  0.1612,  0.4585],\n",
              "                      [-0.4682, -0.2053,  0.5237],\n",
              "                      [-0.2285,  0.3568, -0.0045],\n",
              "                      [-0.0951, -0.2589, -0.3172],\n",
              "                      [ 0.0760, -0.4295, -0.1321],\n",
              "                      [ 0.2592,  0.5644, -0.3319],\n",
              "                      [ 0.2441, -0.5205,  0.1412],\n",
              "                      [-0.4077,  0.4892, -0.5581],\n",
              "                      [ 0.5332,  0.0593,  0.2866],\n",
              "                      [ 0.2356, -0.3729,  0.0448],\n",
              "                      [ 0.3575, -0.5477, -0.4465],\n",
              "                      [ 0.5456,  0.0874, -0.2567],\n",
              "                      [ 0.0455,  0.4494,  0.0925],\n",
              "                      [ 0.3270, -0.0911, -0.5423],\n",
              "                      [ 0.3436, -0.2008, -0.1408],\n",
              "                      [ 0.4312,  0.2203,  0.4744],\n",
              "                      [-0.3890, -0.5191,  0.3130],\n",
              "                      [ 0.1335, -0.3946,  0.4491],\n",
              "                      [-0.3981, -0.4559, -0.1585],\n",
              "                      [-0.2490, -0.2892,  0.0711],\n",
              "                      [-0.3378,  0.0468, -0.1086],\n",
              "                      [ 0.2051, -0.4813,  0.2104],\n",
              "                      [ 0.0126,  0.0182, -0.4261],\n",
              "                      [-0.3465, -0.1998,  0.2947],\n",
              "                      [ 0.3018, -0.0274,  0.3326],\n",
              "                      [-0.1208, -0.3705, -0.5505],\n",
              "                      [-0.1919, -0.4770, -0.3193],\n",
              "                      [ 0.0936,  0.4481, -0.4916],\n",
              "                      [-0.2656, -0.2262,  0.2477],\n",
              "                      [-0.5744,  0.1247, -0.2085],\n",
              "                      [-0.5013,  0.2183, -0.3481],\n",
              "                      [ 0.3278,  0.0493, -0.1374],\n",
              "                      [-0.4685, -0.4875, -0.5606],\n",
              "                      [ 0.1927, -0.3862,  0.4818],\n",
              "                      [ 0.2717,  0.3490, -0.4797],\n",
              "                      [ 0.1453, -0.4993,  0.2581],\n",
              "                      [ 0.4795,  0.3563,  0.4681],\n",
              "                      [-0.5583, -0.5252, -0.0831],\n",
              "                      [ 0.4775, -0.4663,  0.3966],\n",
              "                      [ 0.4570,  0.4994, -0.3754],\n",
              "                      [-0.1588,  0.0590,  0.1445],\n",
              "                      [ 0.5401, -0.2562,  0.3976],\n",
              "                      [-0.2374,  0.3839, -0.0655],\n",
              "                      [-0.1636,  0.3458, -0.5589],\n",
              "                      [-0.4813, -0.2350,  0.4563],\n",
              "                      [ 0.4235, -0.3210,  0.0878],\n",
              "                      [ 0.5200,  0.0330,  0.5643],\n",
              "                      [ 0.3656, -0.3078, -0.3587],\n",
              "                      [-0.5381, -0.2380,  0.5447],\n",
              "                      [-0.1491,  0.3987, -0.1027],\n",
              "                      [ 0.5400, -0.3966,  0.1939],\n",
              "                      [ 0.4805, -0.1432, -0.4162],\n",
              "                      [-0.3054,  0.0848, -0.1344],\n",
              "                      [ 0.3607,  0.2512,  0.5072],\n",
              "                      [-0.1883,  0.1665, -0.4031],\n",
              "                      [ 0.3360, -0.4396,  0.1320],\n",
              "                      [ 0.0700,  0.2182,  0.0662],\n",
              "                      [-0.2466, -0.5422, -0.3788],\n",
              "                      [-0.5045,  0.3525, -0.4662],\n",
              "                      [-0.2230,  0.0415,  0.5505],\n",
              "                      [ 0.1299, -0.4971,  0.2765],\n",
              "                      [ 0.4366, -0.1728,  0.1305],\n",
              "                      [-0.1336,  0.3398, -0.1847],\n",
              "                      [ 0.3251, -0.3594, -0.5379],\n",
              "                      [-0.4821,  0.4677,  0.4543],\n",
              "                      [ 0.2237, -0.0954, -0.1224],\n",
              "                      [-0.5016, -0.3863,  0.1654],\n",
              "                      [ 0.0304, -0.1912, -0.3048],\n",
              "                      [ 0.1829, -0.2152,  0.1989],\n",
              "                      [-0.0618,  0.0681, -0.3263],\n",
              "                      [-0.0282, -0.4117,  0.0648],\n",
              "                      [-0.0506, -0.2855, -0.2419],\n",
              "                      [-0.2312, -0.4004, -0.0356],\n",
              "                      [ 0.2750,  0.4112,  0.3110],\n",
              "                      [ 0.3147,  0.0713, -0.2143],\n",
              "                      [ 0.3648,  0.1454,  0.5220],\n",
              "                      [-0.4188, -0.0284,  0.1901]])),\n",
              "             ('0.bias',\n",
              "              tensor([-0.4968, -0.1709, -0.4199, -0.5089,  0.1605, -0.3069,  0.1651, -0.1815,\n",
              "                       0.0130,  0.1293,  0.5429, -0.1712, -0.1080,  0.4742,  0.0546,  0.2935,\n",
              "                       0.1117, -0.4246,  0.0234, -0.4702,  0.5271,  0.0497,  0.0018, -0.2364,\n",
              "                       0.4297, -0.0371, -0.0874,  0.2031,  0.0517,  0.0032,  0.0333, -0.0950,\n",
              "                      -0.5096,  0.1114,  0.2022, -0.0042,  0.5114, -0.3577,  0.1744, -0.1779,\n",
              "                       0.2103,  0.4261, -0.5517,  0.4330,  0.3722, -0.4507, -0.5455, -0.0826,\n",
              "                       0.0485, -0.1617, -0.0935, -0.1157,  0.2420, -0.0982,  0.3369,  0.3345,\n",
              "                      -0.2821, -0.1540,  0.5440, -0.4417, -0.5547,  0.4106, -0.0817, -0.0517,\n",
              "                      -0.4511, -0.0573, -0.1130, -0.4480,  0.1194,  0.1523,  0.5173,  0.4620,\n",
              "                       0.2471, -0.3473, -0.1751, -0.3534,  0.3661,  0.3169,  0.1004, -0.2605,\n",
              "                      -0.0991, -0.3500, -0.1270,  0.3504,  0.1520, -0.5059,  0.1594,  0.4231,\n",
              "                      -0.3584, -0.3113,  0.1174,  0.2636,  0.0650, -0.0763,  0.1380, -0.0799,\n",
              "                      -0.5205, -0.0315,  0.0038, -0.5280])),\n",
              "             ('1.weight',\n",
              "              tensor([[-0.0110, -0.0779,  0.0631,  ...,  0.0594, -0.0917,  0.0102],\n",
              "                      [-0.0061,  0.0832,  0.0297,  ..., -0.0051, -0.0313,  0.0168],\n",
              "                      [ 0.0778,  0.0402,  0.0828,  ..., -0.0158, -0.0472,  0.0029],\n",
              "                      ...,\n",
              "                      [ 0.0726, -0.0504, -0.0984,  ..., -0.0272,  0.0802, -0.0917],\n",
              "                      [ 0.0403, -0.0462, -0.0660,  ..., -0.0227,  0.0843, -0.0416],\n",
              "                      [ 0.0285, -0.0875,  0.0261,  ..., -0.0431, -0.0340, -0.0751]])),\n",
              "             ('1.bias',\n",
              "              tensor([ 0.0058,  0.0258,  0.0848,  0.0305, -0.0020,  0.0849, -0.0754, -0.0455,\n",
              "                       0.0304,  0.0690, -0.0975,  0.0392,  0.0031, -0.0587, -0.0858,  0.0163,\n",
              "                      -0.0118,  0.0265,  0.0312, -0.0809,  0.0774, -0.0223,  0.0167,  0.0173,\n",
              "                      -0.0351,  0.0809, -0.0891, -0.0004,  0.0086,  0.0202,  0.0760,  0.0733,\n",
              "                      -0.0578, -0.0736, -0.0914,  0.0069, -0.0729,  0.0216,  0.0620, -0.0713,\n",
              "                       0.0970,  0.0170,  0.0368,  0.0365, -0.0435,  0.0453,  0.0782,  0.0171,\n",
              "                       0.0248, -0.0506, -0.0193, -0.0442, -0.0778, -0.0060, -0.0315, -0.0765,\n",
              "                      -0.0660, -0.0445,  0.0005,  0.0344, -0.0900, -0.0834, -0.0592, -0.0529,\n",
              "                       0.0021, -0.0912,  0.0066, -0.0074,  0.0189,  0.0136,  0.0964, -0.0444,\n",
              "                      -0.0927, -0.0963, -0.0772, -0.0344,  0.0697, -0.0438, -0.0470,  0.0401,\n",
              "                       0.0110,  0.0368,  0.0512,  0.0483, -0.0634, -0.0740,  0.0760,  0.0850,\n",
              "                       0.0748, -0.0953, -0.0978, -0.0088,  0.0605, -0.0664, -0.0821,  0.0035,\n",
              "                       0.0527,  0.0269, -0.0010, -0.0322])),\n",
              "             ('3.weight',\n",
              "              tensor([[ 0.0545,  0.0789, -0.0010, -0.0122, -0.0943, -0.0702, -0.0065,  0.0598,\n",
              "                        0.0917, -0.0260, -0.0046, -0.0649, -0.0806, -0.0662, -0.0799, -0.0727,\n",
              "                       -0.0420, -0.0007, -0.0306,  0.0061, -0.0848,  0.0836, -0.0840,  0.0850,\n",
              "                       -0.0099, -0.0256,  0.0743, -0.0201,  0.0164,  0.0564, -0.0769, -0.0839,\n",
              "                        0.0668,  0.0895,  0.0155, -0.0744, -0.0587,  0.0793,  0.0216,  0.0433,\n",
              "                       -0.0417, -0.0353,  0.0127,  0.0924,  0.0250, -0.0165,  0.0212,  0.0918,\n",
              "                        0.0844,  0.0293, -0.0043, -0.0444,  0.0389, -0.0844,  0.0397,  0.0323,\n",
              "                        0.0594,  0.0887,  0.0864,  0.0333,  0.0703,  0.0465,  0.0096,  0.0677,\n",
              "                       -0.0906, -0.0483, -0.0109, -0.0447, -0.0529,  0.0351,  0.0027,  0.0528,\n",
              "                       -0.0077,  0.0435, -0.0473,  0.0987, -0.0744,  0.0724,  0.0933, -0.0578,\n",
              "                        0.0942, -0.0378,  0.0940, -0.0055,  0.0944, -0.0703,  0.0533, -0.0081,\n",
              "                       -0.0144, -0.0307,  0.0721, -0.0284,  0.0611,  0.0559,  0.0067, -0.0932,\n",
              "                        0.0771, -0.0621,  0.0933, -0.0483],\n",
              "                      [-0.0127, -0.0708,  0.0768, -0.0021,  0.0240, -0.0301, -0.0960,  0.0485,\n",
              "                       -0.0846, -0.0986, -0.0574, -0.0479, -0.0583,  0.0100,  0.0683, -0.0094,\n",
              "                        0.0153,  0.0894,  0.0523,  0.0093,  0.0153, -0.0430,  0.0496,  0.0702,\n",
              "                       -0.0965, -0.0652,  0.0896,  0.0632, -0.0229,  0.0544, -0.0709,  0.0367,\n",
              "                        0.0509, -0.0014, -0.0133, -0.0296,  0.0441, -0.0985,  0.0488, -0.0406,\n",
              "                        0.0070,  0.0520,  0.0109,  0.0400,  0.0389,  0.0458,  0.0843,  0.0245,\n",
              "                        0.0740,  0.0307,  0.0792,  0.0986, -0.0313,  0.0272, -0.0122, -0.0970,\n",
              "                       -0.0103, -0.0709,  0.0539,  0.0849,  0.0400,  0.0584,  0.0118,  0.0431,\n",
              "                        0.0350, -0.0321, -0.0130, -0.0331,  0.0880, -0.0147,  0.0473, -0.0831,\n",
              "                       -0.0645,  0.0637,  0.0334, -0.0159, -0.0301, -0.0712, -0.0234,  0.0264,\n",
              "                       -0.0266,  0.0278, -0.0655, -0.0560, -0.0962,  0.0628,  0.0914,  0.0532,\n",
              "                        0.0043, -0.0435,  0.0747, -0.0015, -0.0502, -0.0735,  0.0078,  0.0925,\n",
              "                        0.0792,  0.0120,  0.0829,  0.0373],\n",
              "                      [-0.0770,  0.0916,  0.0844, -0.0542, -0.0978,  0.0265, -0.0966,  0.0022,\n",
              "                        0.0548, -0.0434, -0.0149, -0.0423, -0.0666,  0.0519,  0.0664,  0.0686,\n",
              "                       -0.0122, -0.0641, -0.0747, -0.0191,  0.0768,  0.0174, -0.0144, -0.0398,\n",
              "                        0.0018, -0.0893,  0.0276, -0.0397, -0.0363, -0.0621, -0.0810, -0.0303,\n",
              "                       -0.0411,  0.0649, -0.0028,  0.0386,  0.0557,  0.0774,  0.0238, -0.0893,\n",
              "                       -0.0806, -0.0073,  0.0669, -0.0670, -0.0302,  0.0906, -0.0154, -0.0980,\n",
              "                       -0.0579,  0.0147,  0.0518, -0.0289,  0.0056,  0.0581, -0.0820, -0.0399,\n",
              "                       -0.0367, -0.0496, -0.0713, -0.0284,  0.0301,  0.0753, -0.0951, -0.0027,\n",
              "                        0.0144, -0.0497, -0.0221,  0.0701,  0.0813, -0.0981,  0.0988, -0.0730,\n",
              "                        0.0228,  0.0426,  0.0278,  0.0374,  0.0947,  0.0316, -0.0877, -0.0859,\n",
              "                        0.0401, -0.0568, -0.0816, -0.0975,  0.0123, -0.0106,  0.0952,  0.0071,\n",
              "                        0.0012,  0.0240, -0.0082,  0.0553, -0.0675, -0.0652, -0.0528, -0.0045,\n",
              "                        0.0440, -0.0227, -0.0232,  0.0126]])),\n",
              "             ('3.bias', tensor([ 0.0378, -0.0341, -0.0486]))])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kTnPbXHnVvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}